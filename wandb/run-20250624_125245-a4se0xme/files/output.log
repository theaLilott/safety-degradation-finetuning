  3%|███▎                                                                                                                       | 16/591 [00:10<06:00,  1.60it/s]Traceback (most recent call last):
{'loss': 2.7025, 'grad_norm': 1.6381455659866333, 'learning_rate': 0.0, 'num_tokens': 1267.0, 'mean_token_accuracy': 0.5248606726527214, 'epoch': 0.0}
{'loss': 2.4993, 'grad_norm': 1.6325055360794067, 'learning_rate': 1.6666666666666667e-06, 'num_tokens': 2437.0, 'mean_token_accuracy': 0.547931145876646, 'epoch': 0.0}
{'loss': 2.8759, 'grad_norm': 1.6297266483306885, 'learning_rate': 3.3333333333333333e-06, 'num_tokens': 3424.0, 'mean_token_accuracy': 0.5359566509723663, 'epoch': 0.01}
{'loss': 2.3609, 'grad_norm': 1.3536267280578613, 'learning_rate': 5e-06, 'num_tokens': 5197.0, 'mean_token_accuracy': 0.592402495443821, 'epoch': 0.01}
{'loss': 2.473, 'grad_norm': 1.507548451423645, 'learning_rate': 6.666666666666667e-06, 'num_tokens': 6472.0, 'mean_token_accuracy': 0.5710974894464016, 'epoch': 0.01}
{'loss': 2.6106, 'grad_norm': 1.4934824705123901, 'learning_rate': 8.333333333333334e-06, 'num_tokens': 7809.0, 'mean_token_accuracy': 0.5501666106283665, 'epoch': 0.01}
{'loss': 2.3645, 'grad_norm': 1.5857869386672974, 'learning_rate': 1e-05, 'num_tokens': 8886.0, 'mean_token_accuracy': 0.5707275383174419, 'epoch': 0.01}
{'loss': 2.3233, 'grad_norm': 1.242738962173462, 'learning_rate': 1.1666666666666668e-05, 'num_tokens': 10520.0, 'mean_token_accuracy': 0.5782363936305046, 'epoch': 0.01}
{'loss': 2.3443, 'grad_norm': 1.3109753131866455, 'learning_rate': 1.3333333333333333e-05, 'num_tokens': 12219.0, 'mean_token_accuracy': 0.5927555561065674, 'epoch': 0.02}
{'loss': 2.7368, 'grad_norm': 1.8020223379135132, 'learning_rate': 1.5e-05, 'num_tokens': 13250.0, 'mean_token_accuracy': 0.5619779750704765, 'epoch': 0.02}
{'loss': 2.4993, 'grad_norm': 1.7891497611999512, 'learning_rate': 1.6666666666666667e-05, 'num_tokens': 14312.0, 'mean_token_accuracy': 0.57830710709095, 'epoch': 0.02}
{'loss': 2.4341, 'grad_norm': 1.5946773290634155, 'learning_rate': 1.8333333333333333e-05, 'num_tokens': 15458.0, 'mean_token_accuracy': 0.5843534916639328, 'epoch': 0.02}
{'loss': 2.1381, 'grad_norm': 1.406502604484558, 'learning_rate': 2e-05, 'num_tokens': 16955.0, 'mean_token_accuracy': 0.5937685593962669, 'epoch': 0.02}
{'loss': 2.9264, 'grad_norm': 1.7808349132537842, 'learning_rate': 2.1666666666666667e-05, 'num_tokens': 17993.0, 'mean_token_accuracy': 0.5370889715850353, 'epoch': 0.02}
{'loss': 2.669, 'grad_norm': 1.9109337329864502, 'learning_rate': 2.3333333333333336e-05, 'num_tokens': 18971.0, 'mean_token_accuracy': 0.5317688174545765, 'epoch': 0.03}
{'loss': 2.3284, 'grad_norm': 1.5153268575668335, 'learning_rate': 2.5e-05, 'num_tokens': 20299.0, 'mean_token_accuracy': 0.5843853801488876, 'epoch': 0.03}
  File "/workspace/safety-degradation-finetuning/lora_train.py", line 144, in <module>
    trainer.train()
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2231, in train
    return inner_training_loop(
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2555, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 864, in training_step
    return super().training_step(*args, **kwargs)
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/transformers/trainer.py", line 3791, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 2553, in backward
    loss.backward(**kwargs)
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "/workspace/safety-degradation-finetuning/lora_train.py", line 144, in <module>
    trainer.train()
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2231, in train
    return inner_training_loop(
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2555, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 864, in training_step
    return super().training_step(*args, **kwargs)
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/transformers/trainer.py", line 3791, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/accelerate/accelerator.py", line 2553, in backward
    loss.backward(**kwargs)
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/workspace/safety-degradation-finetuning/venv/lib/python3.10/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
